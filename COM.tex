\documentclass[preprint,12pt]{elsarticle}
    \usepackage{algorithm}
    \usepackage{algorithmic}
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \usepackage{amssymb}
    \usepackage{amsmath}
    \usepackage[hidelinks]{hyperref}
    \usepackage[capitalize]{cleveref}
    \usepackage{xspace} 
    \usepackage{ifthen} 
    \usepackage{csvsimple}
    \setlength {\marginparwidth }{2cm}
    \usepackage{todonotes}
    \usepackage{float}
    \newcommand*{\M}[1]{\ensuremath{#1}\xspace} 
    \newcommand*{\tr}[1]{\M{#1}}
    \newcommand*{\x}{\times}
    \newcommand*{\mi}[1]{\mathbf{#1}} 
    \newcommand*{\st}[1]{\mathbb{#1}} 
    \newcommand*{\rv}[1]{\mathsf{#1}} 
    \newcommand*{\te}[2][]{\left\lbrack{#2}\right\rbrack_{#1}}
    \newcommand*{\tte}[2][]{\lbrack{#2}\rbrack_{#1}}
    \newcommand*{\tse}[2][]{\mi{\lbrack#2\rbrack}_{#1}}
    \newcommand*{\tme}[3][]{\lbrack{#3}\rbrack_{\tse[#1]{#2}}}
    \newcommand*{\diag}[2][]{\left\langle{#2}\right\rangle_{#1}}
    \newcommand*{\prob}[3]{\M{\mathsf{p}\!\left(\left.{#1}\right\vert{#2,#3}\right)}} 
    \newcommand*{\deq}{\M{\mathrel{\mathop:}=}} 
    \newcommand*{\deqr}{\M{=\mathrel{\mathop:}}} 
    \newcommand{\T}[1]{\text{#1}} 
    \newcommand*{\QT}[2][]{\M{\quad\T{#2}\ifthenelse{\equal{#1}{}}{\quad}{#1}}} 
    \newcommand*{\ev}[3][]{\mathbb{E}_{#3}^{#1}\!\left\lbrack{#2}\right\rbrack}
    \newcommand*{\evt}[3][]{\mathbb{E}_{#3}^{#1}\!#2}
    \newcommand*{\cov}[3][]{\ifthenelse{\equal{#1}{}}{\mathbb{V}_{#3}\!\left\lbrack{#2}\right\rbrack}{\mathbb{V}_{#3}\!\left\lbrack{#2,#1}\right\rbrack}}
    \newcommand*{\covt}[2]{\mathbb{V}_{#2}\!{#1}}
    \newcommand*{\gauss}[2]{\mathsf{N}\!\left({#1,#2}\right)}
    \newcommand*{\uni}[2]{\mathsf{U}\!\left({#1,#2}\right)}
    \newcommand*{\tgauss}[2]{\mathsf{N}({#1,#2})}
    \newcommand*{\gaussd}[2]{\mathsf{N}^{\dagger}\!\left({#1,#2}\right)}
    \newcommand*{\modulus}[1]{\M{\left\lvert{#1}\right\rvert}} 
    \newcommand*{\norm}[1]{\M{\left\lVert{#1}\right\rVert}} 
    \newcommand*{\ceil}[1]{\M{\left\lceil{#1}\right\rceil}} 
    \newcommand*{\set}[1]{\M{\left\lbrace{#1}\right\rbrace}} 
    \newcommand*{\setbuilder}[2]{\M{\left\lbrace{#1}\: \big\vert \:{#2}\right\rbrace}}
    \newcommand*{\uniti}{\lbrack 0,1\rbrack}
    \DeclareMathOperator*{\argmax}{argmax}
    \DeclareMathOperator*{\argmin}{argmin}
    \DeclareMathOperator*{\trace}{tr\!}

\journal{Reliability Engineering and System Safety}

\begin{document}
\begin{frontmatter}

    \title{The Coefficient of Determination of a Reduced Order Model}

    \author{Robert A. Milton}
    \ead{r.a.milton@sheffield.ac.uk}

    \author{Solomon F. Brown}
    \ead{s.f.brown@sheffield.ac.uk}

    \author{Aaron S. Yeardley}
    \ead{asyeardley1@sheffield.ac.uk}

    \address{Department of Chemical and Biological Engineering, University of Sheffield, Sheffield, S1 3JD, United Kingdom}       

    \begin{abstract}
        %% Text of abstract
    \end{abstract}

    \begin{keyword}
        Global Sensitivity Analysis, Sobol' Index, Surrogate Model, Active Subspace
    \end{keyword}

\end{frontmatter}


\section{Introduction}\label{sec:Intro}


\section{Coefficient of Deterimnation}\label{sec:COD}
    Given
    \begin{equation*}
        \T{Integrable } y \colon \uniti^{M+1} \mapsto \st{R}^{L}
    \end{equation*}
    take a random variable (RV)
    \begin{equation*}
        \rv{u} \sim \uni{\te[\mi{M+1}]{0}}{\te[\mi{M+1}]{1}} \deq \uni{0}{1}^{M+1}
    \end{equation*}
    Exponentiation is repeated tensor outer product $\otimes$ unless otherwise specified. Tensors are square bracketed quantities, their dimensions listed as a von Neumann ordinal subscript, in this case
    \begin{equation*}
        \mi{M+1} \deq (0,\ldots,M) \supseteq \mi{m+1} \deq (0,\ldots,m \leq M)
    \end{equation*}
    with void $\mi{0}$ voiding any tensor it subscripts. Ordinals are concatenated by Cartesian $\times$ and may be subtracted, as in $\mi{M-m} \deq (m,\ldots,M-1)$.
    Expectations and variances will be subscripted by the dimensions of $\rv{u}$ integrated over (marginalized). Conditioning on the remaining dimensions is left implicit after \cref{def:Theory:y_m}, to lighten notation.

    Construct $M+1$ stochastic processes (SPs)
    \begin{equation}\label{def:Theory:y_m}
        \te[\mi{L}]{\rv{y_m}} \deq \ev{y(\rv{u})}{\mi{M-m}} \deq \ev{y(\rv{u}) \big\vert \te[\mi{m}]{\rv{u}}}{\mi{M-m}}
    \end{equation}
    ranging from $\tte[\mi{L}]{\rv{y_0}}$ to $\tte[\mi{L}]{\rv{y_M}}$. Every one of these quietly depends on the ineradicable noise component $\tte[M]{\rv{u}} \perp \tte[\mi{M}]{\rv{u}}$, while ignoring input components $\tte[\mi{M-m}]{\rv{u}}$. Following Daniell-Kolmogorov \cite{Rogers.Williams2000} pp.124 we may regard an SP as a random function, from we shall freely extract finite dimensional distributions generated by a design matrix $\tte[\mi{M\x o}]{\rv{u}}$ of $o \in \st{Z}^{+}$ sample inputs.

    All other existential issues will be dealt with now. Existence of $\rv{u}$ could be taken for granted, but is rigorously proved at least twice in \cite{Williams1991} pp.34,43,81. 
    Because $y$ is (Lebesgue) integrable it must be (Lebesgue) measurable, guaranteeing $\tte[\mi{L}]{\rv{y_0}}$.
    Because all probability measures are finite, integrability of $y$ implies integrability of $y^n$ for all $n\geq 1$ \cite{Villani1985}. 
    So Fubini's Theorem \cite{Williams1991} pp.77 allows all expectations to be taken in any order. 
    This is sufficient to ensure every object appearing in this work.

    The purpose of this work is to compare predictions from a reduced model $\rv{y_m}$ with those of the full model $\rv{y_M}$. Correlation between these predictions is squared -- using element-wise (Hadamard) multiplication $\circ$ and division -- to form an RV called the coefficient of determination
    \begin{equation}
        \te[\mi{L}^2]{\rv{R_{m}^{2}}} \deq 
        \frac{\cov[\rv{y_M}]{\rv{y_m}}{\mi{M}} \circ \cov[\rv{y_M}]{\rv{y_m}}{\mi{M}}}
        {\cov{\rv{y_m}}{\mi{m}} \circ \cov{\rv{y_M}}{\mi{M}}} =
        \frac{\cov{\rv{y_m}}{\mi{m}}}{\cov{\rv{y_M}}{\mi{M}}} \deqr
        \te[\mi{L}^2]{\rv{S_m}}
    \end{equation}
    The closed Sobol' index is the complement of the widespread total Sobol' index
    \begin{equation*}
        \te[\mi{L}^2]{\rv{S_m}} \deqr \te[\mi{L}^2]{1} - \te[\mi{L}^2]{\rv{S^{T}_{M-m}}}
    \end{equation*}
    It has mean value over the ineradicable noise axis of
    \begin{align}\label{def:COD:mean}
        \te[\mi{L}^2]{S_{\mi{m}}} &\deq \evt{\te[\mi{L}^2]{\rv{S_m}}}{M} = \frac{V_{\mi{m}}}{V_{\mi{M}}} \\            
        V_{\mi{m}} &\deq \evt{\; \cov{\rv{y_m}}{\mi{m}}}{M}
    \end{align}
    and variance over the noise axis
    \begin{align}\label{def:COD:variance}
        \te[\mi{L}\x\mi{L}\x\mi{L}\x\mi{L}]{T_\mi{m}} \deq 
        \covt{\;\te[\mi{L}\x\mi{L}]{\rv{S_m}}}{M} &\phantom{:}= \frac{V_{\mi{m}}^{2}}{V_{\mi{M}}^{2}} \circ
        \left(
            \frac{W_{\mi{m},\mi{m}}}{V_{\mi{m}}^{2}}
            -2\frac{W_{\mi{m},\mi{M}}}{{V_{\mi{m}}\otimes V_{\mi{M}}}}
            +\frac{W_{\mi{M},\mi{M}}}{V_{\mi{M}}^{2}}
        \right) \\                
        \te[\mi{L}^4]{W_{\mi{m},\mi{m^{\prime}}}} &\deq \cov[\cov{\rv{y_{m^{\prime}}}}{\mi{m^{\prime}}}]{\cov{\rv{y_{m}}}{\mi{m}}}{M}
    \end{align}
    The remainder of this paper is devoted to calculating these two quantities: the coefficient of determination and its variance over noise (measurement error, squared).


\section{Stochastic Process Estimates}\label{sec:SP}
    Define mean predictors (functions of $\tte[\mi{m}]{\rv{u}}$) and their error SPs as
    \begin{equation}
        \begin{aligned}
            \te[\mi{L}]{f_{\mi{m}}} &\deq \evt{\te[\mi{L}]{\rv{y_m}}}{\mi{M+1-m}} \\
            \te[\mi{L}]{\rv{e_m}} &\deq \te[\mi{L}]{\rv{y_m}} - \te[\mi{L}]{f_{\mi{m}}} \\
        \end{aligned}
    \end{equation}
    Adopt as design matrix a trio of independent inputs, labelled according to how they will be marginalized
    \begin{equation*}
            \te[\mi{M+1}]{\rv{u}}^3 \deq \left\lbrack \rv{u_0},\rv{u_m},\rv{u_M} \right\rbrack
    \end{equation*}
    eliciting
    \begin{equation*}
        \te[\mi{L}]{\rv{e}}^3 \deq y(\tte[\mi{M+1}]{\rv{u}}^3) - \evt{\;\evt{\;\ev{y(\tte[\mi{M+1}]{\rv{u}}^3)}{M^{\prime\prime}}}{\mi{M^{\prime}+1^{\prime}-m^{\prime}}}}{\mi{M+1}}
    \end{equation*}
    Primes mark independent dimensions, otherwise each expectation applies to every component of $\tte[\mi{M+1}]{\rv{u}}^3$. The latter occurs when calculating sub-tensors of moments of $\te[\mi{L}]{\rv{e}}^3$
    \begin{equation*}
        \te[\mi{L}^{n}]{\mu_{\mi{m^{\prime},\ldots,m}^{n\prime}}} \sqsubset \te[(\mi{L\x 3})^{n}]{\mu_{n}} \deq \ev{\te[]{\tte[\mi{L}]{\rv{e}}^{3}}^{n}}{M} \deq \evt{\cdots\ev{\te[]{\tte[\mi{L}]{\rv{e}}^{3}}^{n}}{M}}{M}
    \end{equation*}
    for $\mi{m}^{i\prime} \in \set{\mi{0},\mi{m},\mi{M}}$. This calculation is the purpose behind introducing the trio design matrix. Care is needed when deciding which dimensions are independent, which is determined by the measure behind an expectation. Iterated expectations do not arise naturally here, so when they are seen they generally must be ``primed''.

    The expected variance in \cref{def:COD:mean} is now readily calculated as
    \begin{equation}
        \begin{aligned}
            V_{\mi{m}} 
            &= \evt{\;\ev{\te[\mi{L}]{\rv{e_m} + f_{\mi{m}}}^{2}}{M}}{\mi{m}}
            - \ev{\te[\mi{L}]{\rv{e_0} + f_{\mi{0}}}^{2}}{M} \\
            &= \ev{\te[\mi{L}]{f_{\mi{m}}}^{2}}{\mi{m}} - \te[\mi{L}]{f_{\mi{0}}}^{2} + 
            \evt{\te[\mi{L}^2]{\mu_{\mi{m,m}}}}{\mi{m}} - \te[\mi{L}^2]{\mu_{\mi{0,0}}} \\
            &= \ev{\te[\mi{L}]{f_{\mi{m}}}^{2}}{\mi{m}} - \te[\mi{L}]{f_{\mi{0}}}^{2}
        \end{aligned}
    \end{equation}

    The covariance between variances in \cref{def:COD:variance} is
    \begin{equation*}
        \begin{aligned}
            \te[\mi{L}^4]{W_{\mi{m},\mi{m^{\prime}}}} &\deq \cov[\cov{\rv{y_{m^{\prime}}}}{\mi{m^{\prime}}}]{\cov{\rv{y_{m}}}{\mi{m}}}{\mi{L}} \\
            &\phantom{:}=
            \cov[\ev{\te[\mi{L}]{\rv{y_{m^{\prime}}}}^{2} - \te[\mi{L}]{\rv{y_{0}}}^{2}}{\mi{m^{\prime}}}]{\ev{\te[\mi{L}]{\rv{y_{m}}}^{2} - \te[\mi{L}]{\rv{y_{0}}}^{2}}{\mi{m}}}{\mi{L}} \\
            &\phantom{:}=
            \ev{\ev{\te[\mi{L}]{\rv{y_{m}}}^{2} - \te[\mi{L}]{\rv{y_{0}}}^{2}}{\mi{m}} \otimes\ev{\te[\mi{L}]{\rv{y_{m^{\prime}}}}^{2} - \te[\mi{L}]{\rv{y_{0}}}^{2}}{\mi{m^{\prime}}}}{\mi{L}}\\
            &\phantom{\deq}\  - \te[\mi{L}^2]{V_{\mi{m}}}\otimes \te[\mi{L}^2]{V_{\mi{m^{\prime}}}} \\       
            &\phantom{:}= \te[\mi{L}^4]{A_{\mi{m,m^{\prime}}}-A_{\mi{0,m^{\prime}}}-A_{\mi{m,0}}+A_{\mi{0,0}}}
        \end{aligned}
    \end{equation*}
    Here, for any $\mi{m},\mi{m^{\prime}}\subseteq\mi{M}$
    \begin{equation*}
        \begin{aligned}
            \te[\mi{L}^4]{A_{\mi{m},\mi{m^{\prime}}}}
            &\deq \evt{\;\evt{\;\ev{\te[\mi{L}]{\rv{y_{m}}}^{2} \otimes \te[\mi{L}]{\rv{y_{m^{\prime}}}}^{2}}{\mi{L}}}{\mi{m^{\prime}}}}{\mi{m}} - \te[\mi{L}^2]{V_{\mi{m}}}\otimes \te[\mi{L}^2]{V_{\mi{m^{\prime}}}} \\
            &\phantom{:}= \evt{\;\evt{\;\ev{\te[\mi{L}]{\rv{e_{m}}+f_{\mi{m}}}^{2} \otimes \te[\mi{L}]{\rv{e_{m^{\prime}}}+ f_{\mi{m^{\prime}}}}^{2}}{\mi{L}}}{\mi{m^{\prime}}}}{\mi{m}}
            - \te[\mi{L}^2]{V_{\mi{m}}}\otimes \te[\mi{L}^2]{V_{\mi{m^{\prime}}}}
        \end{aligned}
    \end{equation*}
    exploiting the fact that $\tte[\mi{L}^2]{V_{\mi{0}}} = \tte[\mi{L}^2]{0}$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\bibliographystyle{elsarticle-num} 
\bibliography{master}
\end{document}
\endinput
